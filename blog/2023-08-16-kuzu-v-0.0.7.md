---
slug: kuzu-0.0.7-release
authors: [team]
tags: [release]
---

# Kùzu 0.0.7 Release <!-- omit from toc -->
We are very happy to release Kùzu 0.0.7 today! This release comes with the following new main features and improvements: 

- [Node Group Based Node Table Storage](#node-group-based-node-table-storage)
- [Cypher Features](#cypher-features)
  - [Merge Clause](#merge-clause)
  - [Create Macro](#create-macro)
  - [Multi-label Create/Set/Delete](#multi-label-createsetdelete)
  - [Return After Update](#return-after-update)
- [Unnest Arbitrary Subqueries](#unnest-arbitrary-subqueries)
- [Data Export](#data-export)
- [Data Types](#data-types)
  - [MAP](#map)
  - [UNION](#union)
- [Client APIs](#client-apis)
  - [C++ UDF](#c-udf)
  - [Arrow related conversion](#arrow-related-conversion)

<!--truncate-->

For installing the new version, 
please visit the [download section of our website](https://kuzudb.com/#download) 
and [getting started guide](https://kuzudb.com/docusaurus/getting-started/) and the full
[release notes are here](https://github.com/kuzudb/kuzu/releases). 

## Node Group Based Node Table Storage
This release changes the storage layout of node tables to be node group-based.
Before this release, we store each column contiguously in separate files.
Each column contains one data file (e.g., `n-1.col`) and one null file (e.g., `n-1.null`) if the column may contain null values.
This design poses two problems: 1) it comes with many files in the database directory, which can lead to `too many open files` error on systems with a small value for max number of open files; 2) it is not optimized for data compression, which is one great advantage of columnar storage. Partitioning each column into multiple chunks can offer more flexibility as each column chunk can be compressed and decompressed independently compared to compressing the whole column at one time.

In the new design, we introduce the concept of *NodeGroup*, which is equivalent to *RowGroup*, commonly phrased in columnar file formats (e.g., Orc and Parquet), in the sense that they both represent a horizontal partition of a table. We use the term NodeGroup mainly due to that we also partition rel tables based on their src/dst nodes, instead of number of rows.
Within a node group, each property of the table has a chunk of its data stored sequentially in the file. Each column chunk is independent, and can be compressed using different algorithms.

In this release, we've integrated node group-based storage design with node tables together with compressing null and bools into bits.
Now all column data of node tables are now stored in a single file `data.kz`.[^1]
The integration with rel tables and more powerful compression schemes, e.g., constant compression, bitpacking, dictionary compression, will come soon.
For details on our new design, please visit [this issue](https://github.com/kuzudb/kuzu/issues/1474).

[^1]: Primary key index files are still kept separately, but eventually they will also be merged into the `data.kz` file.

## Cypher Features

### Merge Clause
This release introduces `MERGE` clause which is an updating clause that will first try to match the given pattern and, if not found, create the pattern. At a high level, `MERGE <pattern>` can be interpreted as `If MATCH <pattern> then RETURN <pattern> ELES CREATE <patten>`. Additionally, user can specify further `SET` operation based on whether the pattern is found or not through `ON CREATE` and `ON MATCH`.

For example, the following query tries to merge a user node with name "Adam". Since the tuple exists in the database, we update its age property and return the tuple.
```
MERGE (n:User {name : 'Adam'}) ON MATCH SET n.age = 35 RETURN n.*;
------------------
| n.name | n.age |
------------------
| Adam   | 35    |
------------------
```
Below is another example where we try to merge a follows edge since 2022 between "Adam" and "Karissa". Since no such edge exists, we create the edge and set the since property to 1999.
```
MATCH (a:User), (b:User) 
WHERE a.name = 'Adam' AND b.name = 'Karissa' 
MERGE (a)-[e:Follows {since:2022}]->(b) 
ON CREATE SET e.since = 1999
RETURN e;
---------------------------------------------------------
| e                                                     |
---------------------------------------------------------
| (0:0)-{_LABEL: Follows, _ID: 0:5, since: 1999}->(0:1) |
---------------------------------------------------------
```

### Create Macro 

### Multi-label Create/Set/Delete

### Return After Update

## Unnest Arbitrary Subqueries

Consider the following query that finds the name of user follows at least one user that is younger.
```
MATCH (a:User) 
WHERE EXISTS { MATCH (a)-[:Follows]->(b:User) WHERE a.age > b.age } 
RETURN a.name;
```
The query inside `EXISTS` is a correlated subquery and very expensive to evaluate because the inner subquery need to be evaluated for each tuple of "a" with nested loop join. 

In this release, we implemented unnest correlated subquery based on the paper [Unnesting Arbitrary Queries](Unnesting Arbitrary Queries) and move to hash join based solution. The following plan will be generated for the above query.

```
        Hash Join
  /          |        \
Scan(t1)  Build(t2)  Build(t1)
             |          |
          Extend(b)   Scan(a)
             |
         Distinct()
             |
          Scan(t1)
```

The plan executed from right to left. We first scan table `a` from disk and materialize a hash table `t1`, `t1` is then scanned in the middle pipeline for subquery evaluation whose result is materialized as hash table `t2`. Finally, we scan `t1` again in the left pipeline and probe `t2` to perform the hash join. In such case, we avoid repeated evaluation of subquery for each input. More details will come in a separate blog post.

## Data Export
Kùzu now supports export query results to CSV files using the `COPY TO` command. This feature enables seamless extraction of query outputs into CSV format. By default, headers are included, and data fields are comma-separated. For instance:

```
COPY (MATCH (p:person) RETURN p.ID, p.name) TO 'person.csv';
```

The resulting CSV file maintains the query's structure:

```
p.ID,p.name
0,"Alice"
2,"Bob"
3,"Carol"
5,"Dan"
9,"Greg"
...
```

Even nested data types like lists and structs are appropriately captured in the exported CSV. This enhancement simplifies data export and facilitates compatibility with external tools and systems. See [Data Export](../data-export/) on our documentation for more information.
## Data Types

### MAP

### UNION

## Client APIs

### C++ UDF
Ziyi

### Arrow related conversion
Ben
