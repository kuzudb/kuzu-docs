---
title: "LLM Extension"
---

The **LLM extension** provides an interface to fetch text embeddings from supported providers and their models.

It can be installed and loaded using the following commands:

```sql
INSTALL llm;
LOAD llm;
```

See the list of providers and their embedding documentation.

* [OpenAI](https://platform.openai.com/docs/guides/embeddings)
* [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html)
* [Google Vertex](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)
* [Google Gemini](https://ai.google.dev/gemini-api/docs/embeddings)
* [Voyage AI](https://docs.voyageai.com/docs/embeddings)
* [Ollama](https://ollama.com/blog/embedding-models)
---

## Usage

### Configuration

The LLM extension supports configurable options such as credentials, dimensions, and region where applicable.

- All credentials are provided through environment variables.
- Dimensions and region are passed to the `CREATE_EMBEDDING` function call, when supported.

The following environment variables must be set for the corresponding providers:

| Provider | Required Environment Variables |
| --- | --- |
| `amazon-bedrock` | `AWS_ACCESS_KEY`, `AWS_SECRET_ACCESS_KEY` |
| `google-vertex` | `GOOGLE_CLOUD_PROJECT_ID`, `GOOGLE_VERTEX_ACCESS_KEY` |
| `google-gemini` | `GOOGLE_GEMINI_API_KEY` |
| `open-ai` | `OPENAI_API_KEY` |
| `voyage-ai` | `VOYAGE_API_KEY` |

:::note[Note]
The `ollama` provider does not need any configured environment variables but expects the embedding model to be available at `http://localhost:11434`.
:::
---

## Embedding Function

The core feature of the LLM extension is a scalar function that generates text embeddings.

```sql
// Syntax for calling CREATE_EMBEDDING.
CALL CREATE_EMBEDDING(
    'prompt',
    'provider',
    'model',
     dimensions,
    'region',
); // Returns LIST[FLOAT].
```

### Parameters

| Option | Description | 
|--------|-------------| 
| prompt    |The input text to embed.|
| provider    |The embedding provider, e.g., `'open-ai'`, `'ollama'`, `'voyage-ai'`, etc.|
| model    |The identifier of the embedding model. This may change overtime; reference the provider's API reference before use.|
| dimensions    |*(optional)*: The size of the embedding vector to be returned, if supported by the provider. Must be a positive integer. Currently only `'open-ai'`, `'google-vertex'`, `'voyage-ai'` are supported.|
| region    |*(optional)*: A region or endpoint hint, if supported by the provider.|

:::note[Note]
If an unsupported region, model or dimension is specified, the API call to the provider will result in an error. It is highly recommended to check the provider's API reference before use.
:::

### Examples

```sql
CALL CREATE_EMBEDDING("Hello world", "open-ai", "text-embedding-3-small");

CALL CREATE_EMBEDDING("Hello world", "ollama", "nomic-embed-text");

CALL CREATE_EMBEDDING("Hello world", "google-gemini", "gemini-embedding-exp-03-07");
```

With optional parameters:

```sql
CALL CREATE_EMBEDDING("Hello world", "voyage-ai", "voyage-3-large", 512);

CALL CREATE_EMBEDDING("Hello world", "amazon-bedrock", "amazon.titan-embed-text-v1", "us-east-1");

CALL CREATE_EMBEDDING("Hello world", "google-vertex", "gemini-embedding-001", 256, "us-east1");
```
---

## Using embeddings with the vector extension
The embedding function can be used with the vector extension. The example in the [vector docs](/extensions/vector) describes how the `CREATE_EMBEDDING` function can be leveraged to make the vector extension easier to use.
